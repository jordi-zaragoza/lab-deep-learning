{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf # Library to construct neural newtorks. Low level library\n",
    "from tensorflow import keras #Â High level library to handle tensorflow.\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout # Types of layers to use in our neural network.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Tic Tac Toe\n",
    "\n",
    "In this lab you will perform deep learning analysis on a dataset of playing [Tic Tac Toe](https://en.wikipedia.org/wiki/Tic-tac-toe).\n",
    "\n",
    "There are 9 grids in Tic Tac Toe that are coded as the following picture shows:\n",
    "\n",
    "![Tic Tac Toe Grids](tttboard.jpg)\n",
    "\n",
    "In the first 9 columns of the dataset you can find which marks (`x` or `o`) exist in the grids. If there is no mark in a certain grid, it is labeled as `b`. The last column is `class` which tells you whether Player X (who always moves first in Tic Tac Toe) wins in this configuration. Note that when `class` has the value `False`, it means either Player O wins the game or it ends up as a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps suggested below to conduct a neural network analysis using Tensorflow and Keras. You will build a deep learning model to predict whether Player X wins the game or not.\n",
    "\n",
    "## Step 1: Data Engineering\n",
    "\n",
    "This dataset is almost in the ready-to-use state so you do not need to worry about missing values and so on. Still, some simple data engineering is needed.\n",
    "\n",
    "1. Read `tic-tac-toe.csv` into a dataframe.\n",
    "1. Inspect the dataset. Determine if the dataset is reliable by eyeballing the data.\n",
    "1. Convert the categorical values to numeric in all columns.\n",
    "1. Separate the inputs and output.\n",
    "1. Normalize the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tic-tac-toe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TL TM TR ML MM MR BL BM BR  class\n",
       "0  x  x  x  x  o  o  x  o  o   True\n",
       "1  x  x  x  x  o  o  o  x  o   True\n",
       "2  x  x  x  x  o  o  o  o  x   True\n",
       "3  x  x  x  x  o  o  o  b  b   True\n",
       "4  x  x  x  x  o  o  b  o  b   True"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = 'class')\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x):\n",
    "    if x == 'x':\n",
    "        return 1\n",
    "    elif x == 'o':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].apply(lambda x: function(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>958 rows Ã 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR\n",
       "0     1   1   1   1   0   0   1   0   0\n",
       "1     1   1   1   1   0   0   0   1   0\n",
       "2     1   1   1   1   0   0   0   0   1\n",
       "3     1   1   1   1   0   0   0  -1  -1\n",
       "4     1   1   1   1   0   0  -1   0  -1\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
       "953   0   1   1   1   0   0   0   1   1\n",
       "954   0   1   0   1   1   0   1   0   1\n",
       "955   0   1   0   1   0   1   1   0   1\n",
       "956   0   1   0   0   1   1   1   0   1\n",
       "957   0   0   1   1   1   0   0   1   1\n",
       "\n",
       "[958 rows x 9 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "953    False\n",
       "954    False\n",
       "955    False\n",
       "956    False\n",
       "957    False\n",
       "Name: class, Length: 958, dtype: bool"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y.apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Series name: class\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "958 non-null    bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 1.1 KB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Neural Network\n",
    "\n",
    "To build the neural network, you can refer to your own codes you wrote while following the [Deep Learning with Python, TensorFlow, and Keras tutorial](https://www.youtube.com/watch?v=wQ8BIBpya2k) in the lesson. It's pretty similar to what you will be doing in this lab.\n",
    "\n",
    "1. Split the training and test data.\n",
    "1. Create a `Sequential` model.\n",
    "1. Add several layers to your model. Make sure you use ReLU as the activation function for the middle layers. Use Softmax for the output layer because each output has a single lable and all the label probabilities add up to 1.\n",
    "1. Compile the model using `adam` as the optimizer and `sparse_categorical_crossentropy` as the loss function. For metrics, use `accuracy` for now.\n",
    "1. Fit the training data.\n",
    "1. Evaluate your neural network model with the test data.\n",
    "1. Save your model as `tic-tac-toe.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 9)\n",
      "(288, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=7)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.concat([X,y],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_268 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 3)                 30        \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124\n",
      "Trainable params: 124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Callbacks are Keras tools to kepp track of the training progress\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping # This callback allows you to stop the training if the validation error increases\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # This callback allows you to save the model.\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5) \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(units = 9,input_dim = X_train.shape[1],activation='relu'))\n",
    "model.add(Dense(units = 3,activation='relu'))\n",
    "model.add(Dense(units = 1, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam', # Optimization method\n",
    "              loss='mse', # Error metric to minimize\n",
    "              metrics=['accuracy'] # Error matrics to report. But only the \"loss\" will be used for minimization.\n",
    "              )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'reg-nn1.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, # Where to save the checkpoint.\n",
    "    save_freq='epoch', # How often the checkpoint file will be saved.\n",
    "    save_weights_only=False, # Wether or not save only the weitgths of each neuron.\n",
    "    verbose=1 # To display the progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\n",
      "Epoch 1: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.4434 - accuracy: 0.3806 - val_loss: 0.3951 - val_accuracy: 0.4627 - 332ms/epoch - 3ms/step\n",
      "Epoch 2/60\n",
      "\n",
      "Epoch 2: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.3280 - accuracy: 0.5317 - val_loss: 0.3420 - val_accuracy: 0.5299 - 90ms/epoch - 829us/step\n",
      "Epoch 3/60\n",
      "\n",
      "Epoch 3: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2914 - accuracy: 0.5728 - val_loss: 0.3161 - val_accuracy: 0.5672 - 97ms/epoch - 902us/step\n",
      "Epoch 4/60\n",
      "\n",
      "Epoch 4: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2655 - accuracy: 0.5933 - val_loss: 0.2969 - val_accuracy: 0.5597 - 95ms/epoch - 879us/step\n",
      "Epoch 5/60\n",
      "\n",
      "Epoch 5: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2450 - accuracy: 0.6213 - val_loss: 0.2735 - val_accuracy: 0.5896 - 95ms/epoch - 884us/step\n",
      "Epoch 6/60\n",
      "\n",
      "Epoch 6: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2317 - accuracy: 0.6493 - val_loss: 0.2531 - val_accuracy: 0.6119 - 89ms/epoch - 825us/step\n",
      "Epoch 7/60\n",
      "\n",
      "Epoch 7: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2183 - accuracy: 0.6623 - val_loss: 0.2306 - val_accuracy: 0.6269 - 99ms/epoch - 921us/step\n",
      "Epoch 8/60\n",
      "\n",
      "Epoch 8: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2071 - accuracy: 0.6772 - val_loss: 0.2138 - val_accuracy: 0.6493 - 84ms/epoch - 778us/step\n",
      "Epoch 9/60\n",
      "\n",
      "Epoch 9: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1999 - accuracy: 0.6959 - val_loss: 0.2035 - val_accuracy: 0.6493 - 88ms/epoch - 819us/step\n",
      "Epoch 10/60\n",
      "\n",
      "Epoch 10: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1928 - accuracy: 0.7127 - val_loss: 0.1940 - val_accuracy: 0.7090 - 96ms/epoch - 893us/step\n",
      "Epoch 11/60\n",
      "\n",
      "Epoch 11: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1872 - accuracy: 0.7295 - val_loss: 0.1845 - val_accuracy: 0.7537 - 90ms/epoch - 830us/step\n",
      "Epoch 12/60\n",
      "\n",
      "Epoch 12: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1810 - accuracy: 0.7500 - val_loss: 0.1788 - val_accuracy: 0.7612 - 103ms/epoch - 950us/step\n",
      "Epoch 13/60\n",
      "\n",
      "Epoch 13: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1768 - accuracy: 0.7724 - val_loss: 0.1722 - val_accuracy: 0.7836 - 102ms/epoch - 940us/step\n",
      "Epoch 14/60\n",
      "\n",
      "Epoch 14: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1717 - accuracy: 0.7780 - val_loss: 0.1673 - val_accuracy: 0.7910 - 102ms/epoch - 940us/step\n",
      "Epoch 15/60\n",
      "\n",
      "Epoch 15: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1684 - accuracy: 0.7761 - val_loss: 0.1617 - val_accuracy: 0.7910 - 98ms/epoch - 910us/step\n",
      "Epoch 16/60\n",
      "\n",
      "Epoch 16: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1638 - accuracy: 0.7854 - val_loss: 0.1578 - val_accuracy: 0.8134 - 92ms/epoch - 849us/step\n",
      "Epoch 17/60\n",
      "\n",
      "Epoch 17: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1603 - accuracy: 0.7836 - val_loss: 0.1528 - val_accuracy: 0.8209 - 86ms/epoch - 793us/step\n",
      "Epoch 18/60\n",
      "\n",
      "Epoch 18: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1558 - accuracy: 0.7910 - val_loss: 0.1487 - val_accuracy: 0.8284 - 84ms/epoch - 777us/step\n",
      "Epoch 19/60\n",
      "\n",
      "Epoch 19: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1526 - accuracy: 0.7966 - val_loss: 0.1449 - val_accuracy: 0.8134 - 97ms/epoch - 898us/step\n",
      "Epoch 20/60\n",
      "\n",
      "Epoch 20: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1493 - accuracy: 0.8078 - val_loss: 0.1431 - val_accuracy: 0.8209 - 96ms/epoch - 886us/step\n",
      "Epoch 21/60\n",
      "\n",
      "Epoch 21: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1468 - accuracy: 0.7985 - val_loss: 0.1414 - val_accuracy: 0.8284 - 97ms/epoch - 900us/step\n",
      "Epoch 22/60\n",
      "\n",
      "Epoch 22: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1437 - accuracy: 0.8134 - val_loss: 0.1389 - val_accuracy: 0.8358 - 107ms/epoch - 989us/step\n",
      "Epoch 23/60\n",
      "\n",
      "Epoch 23: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1411 - accuracy: 0.8153 - val_loss: 0.1376 - val_accuracy: 0.8358 - 99ms/epoch - 921us/step\n",
      "Epoch 24/60\n",
      "\n",
      "Epoch 24: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1394 - accuracy: 0.8153 - val_loss: 0.1356 - val_accuracy: 0.8433 - 91ms/epoch - 846us/step\n",
      "Epoch 25/60\n",
      "\n",
      "Epoch 25: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1367 - accuracy: 0.8172 - val_loss: 0.1350 - val_accuracy: 0.8060 - 99ms/epoch - 918us/step\n",
      "Epoch 26/60\n",
      "\n",
      "Epoch 26: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1353 - accuracy: 0.8284 - val_loss: 0.1346 - val_accuracy: 0.8433 - 99ms/epoch - 912us/step\n",
      "Epoch 27/60\n",
      "\n",
      "Epoch 27: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1333 - accuracy: 0.8284 - val_loss: 0.1324 - val_accuracy: 0.8209 - 111ms/epoch - 1ms/step\n",
      "Epoch 28/60\n",
      "\n",
      "Epoch 28: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1319 - accuracy: 0.8284 - val_loss: 0.1302 - val_accuracy: 0.8209 - 98ms/epoch - 908us/step\n",
      "Epoch 29/60\n",
      "\n",
      "Epoch 29: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1300 - accuracy: 0.8340 - val_loss: 0.1303 - val_accuracy: 0.8209 - 97ms/epoch - 902us/step\n",
      "Epoch 30/60\n",
      "\n",
      "Epoch 30: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1284 - accuracy: 0.8340 - val_loss: 0.1293 - val_accuracy: 0.8209 - 90ms/epoch - 833us/step\n",
      "Epoch 31/60\n",
      "\n",
      "Epoch 31: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1265 - accuracy: 0.8358 - val_loss: 0.1285 - val_accuracy: 0.8209 - 103ms/epoch - 954us/step\n",
      "Epoch 32/60\n",
      "\n",
      "Epoch 32: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1250 - accuracy: 0.8507 - val_loss: 0.1275 - val_accuracy: 0.8209 - 98ms/epoch - 903us/step\n",
      "Epoch 33/60\n",
      "\n",
      "Epoch 33: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1243 - accuracy: 0.8414 - val_loss: 0.1284 - val_accuracy: 0.8209 - 95ms/epoch - 883us/step\n",
      "Epoch 34/60\n",
      "\n",
      "Epoch 34: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1222 - accuracy: 0.8377 - val_loss: 0.1267 - val_accuracy: 0.8134 - 104ms/epoch - 959us/step\n",
      "Epoch 35/60\n",
      "\n",
      "Epoch 35: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1209 - accuracy: 0.8414 - val_loss: 0.1269 - val_accuracy: 0.8284 - 90ms/epoch - 831us/step\n",
      "Epoch 36/60\n",
      "\n",
      "Epoch 36: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1198 - accuracy: 0.8451 - val_loss: 0.1275 - val_accuracy: 0.8209 - 108ms/epoch - 998us/step\n",
      "Epoch 37/60\n",
      "\n",
      "Epoch 37: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1196 - accuracy: 0.8377 - val_loss: 0.1278 - val_accuracy: 0.8134 - 92ms/epoch - 856us/step\n",
      "Epoch 38/60\n",
      "\n",
      "Epoch 38: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1184 - accuracy: 0.8489 - val_loss: 0.1268 - val_accuracy: 0.8284 - 90ms/epoch - 835us/step\n",
      "Epoch 39/60\n",
      "\n",
      "Epoch 39: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1166 - accuracy: 0.8507 - val_loss: 0.1256 - val_accuracy: 0.8284 - 93ms/epoch - 862us/step\n",
      "Epoch 40/60\n",
      "\n",
      "Epoch 40: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1152 - accuracy: 0.8526 - val_loss: 0.1276 - val_accuracy: 0.8209 - 96ms/epoch - 887us/step\n",
      "Epoch 41/60\n",
      "\n",
      "Epoch 41: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1149 - accuracy: 0.8470 - val_loss: 0.1264 - val_accuracy: 0.8284 - 102ms/epoch - 944us/step\n",
      "Epoch 42/60\n",
      "\n",
      "Epoch 42: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1144 - accuracy: 0.8545 - val_loss: 0.1257 - val_accuracy: 0.8433 - 89ms/epoch - 820us/step\n",
      "Epoch 43/60\n",
      "\n",
      "Epoch 43: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1132 - accuracy: 0.8582 - val_loss: 0.1260 - val_accuracy: 0.8358 - 90ms/epoch - 836us/step\n",
      "Epoch 44/60\n",
      "\n",
      "Epoch 44: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1122 - accuracy: 0.8601 - val_loss: 0.1223 - val_accuracy: 0.8433 - 84ms/epoch - 776us/step\n",
      "Epoch 45/60\n",
      "\n",
      "Epoch 45: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1115 - accuracy: 0.8657 - val_loss: 0.1237 - val_accuracy: 0.8284 - 98ms/epoch - 910us/step\n",
      "Epoch 46/60\n",
      "\n",
      "Epoch 46: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1110 - accuracy: 0.8694 - val_loss: 0.1247 - val_accuracy: 0.8284 - 90ms/epoch - 833us/step\n",
      "Epoch 47/60\n",
      "\n",
      "Epoch 47: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1107 - accuracy: 0.8619 - val_loss: 0.1242 - val_accuracy: 0.8358 - 88ms/epoch - 816us/step\n",
      "Epoch 48/60\n",
      "\n",
      "Epoch 48: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1106 - accuracy: 0.8750 - val_loss: 0.1219 - val_accuracy: 0.8284 - 98ms/epoch - 909us/step\n",
      "Epoch 49/60\n",
      "\n",
      "Epoch 49: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1096 - accuracy: 0.8750 - val_loss: 0.1227 - val_accuracy: 0.8358 - 99ms/epoch - 921us/step\n",
      "Epoch 50/60\n",
      "\n",
      "Epoch 50: saving model to reg-nn1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 0s - loss: 0.1092 - accuracy: 0.8675 - val_loss: 0.1213 - val_accuracy: 0.8284 - 83ms/epoch - 764us/step\n",
      "Epoch 51/60\n",
      "\n",
      "Epoch 51: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1085 - accuracy: 0.8713 - val_loss: 0.1216 - val_accuracy: 0.8433 - 85ms/epoch - 790us/step\n",
      "Epoch 52/60\n",
      "\n",
      "Epoch 52: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1075 - accuracy: 0.8713 - val_loss: 0.1218 - val_accuracy: 0.8284 - 93ms/epoch - 865us/step\n",
      "Epoch 53/60\n",
      "\n",
      "Epoch 53: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1070 - accuracy: 0.8806 - val_loss: 0.1203 - val_accuracy: 0.8507 - 98ms/epoch - 908us/step\n",
      "Epoch 54/60\n",
      "\n",
      "Epoch 54: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1064 - accuracy: 0.8787 - val_loss: 0.1222 - val_accuracy: 0.8358 - 87ms/epoch - 807us/step\n",
      "Epoch 55/60\n",
      "\n",
      "Epoch 55: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1053 - accuracy: 0.8750 - val_loss: 0.1197 - val_accuracy: 0.8358 - 94ms/epoch - 872us/step\n",
      "Epoch 56/60\n",
      "\n",
      "Epoch 56: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1053 - accuracy: 0.8750 - val_loss: 0.1206 - val_accuracy: 0.8358 - 86ms/epoch - 800us/step\n",
      "Epoch 57/60\n",
      "\n",
      "Epoch 57: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1049 - accuracy: 0.8731 - val_loss: 0.1204 - val_accuracy: 0.8433 - 96ms/epoch - 887us/step\n",
      "Epoch 58/60\n",
      "\n",
      "Epoch 58: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1040 - accuracy: 0.8806 - val_loss: 0.1255 - val_accuracy: 0.8358 - 100ms/epoch - 924us/step\n",
      "Epoch 59/60\n",
      "\n",
      "Epoch 59: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1047 - accuracy: 0.8806 - val_loss: 0.1215 - val_accuracy: 0.8433 - 95ms/epoch - 879us/step\n",
      "Epoch 60/60\n",
      "\n",
      "Epoch 60: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1040 - accuracy: 0.8787 - val_loss: 0.1232 - val_accuracy: 0.8358 - 98ms/epoch - 910us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=60, # Number of epochs. \n",
    "    validation_split=0.20, # Here the TRAIN set will be split in TRAIN = TRAIN_NEW + VALIDATION. TRAIN_NEW used for train and val for CV\n",
    "    batch_size=5, # How many samples to input in the network before updating the weights\n",
    "    verbose=2, # To display the progress.\n",
    "    callbacks=[early_stopping,checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(history, metric):\n",
    "    train_metrics = history.history[metric]\n",
    "    val_metrics = history.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics)\n",
    "    plt.plot(epochs, val_metrics)\n",
    "    plt.title('Training and validation '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.yscale('log')\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(history,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical cross entropy gives nan, the model is not ok, i used mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make Predictions\n",
    "\n",
    "Now load your saved model and use it to make predictions on a few random rows in the test dataset. Check if the predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(y_train, y_pred_train, y_test, y_pred_test):\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "    ME_train = np.mean(y_train-y_pred_train)\n",
    "    ME_test  = np.mean(y_test-y_pred_test)\n",
    "\n",
    "    MAE_train = mean_absolute_error(y_train,y_pred_train)\n",
    "    MAE_test  = mean_absolute_error(y_test,y_pred_test)\n",
    "\n",
    "    MSE_train = mean_squared_error(y_train,y_pred_train)\n",
    "    MSE_test  = mean_squared_error(y_test,y_pred_test)\n",
    "\n",
    "    RMSE_train = np.sqrt(MSE_train)\n",
    "    RMSE_test  = np.sqrt(MSE_test)\n",
    "\n",
    "    MAPE_train = np.mean((np.abs(y_train-y_pred_train) / y_train)* 100.)\n",
    "    MAPE_test  = np.mean((np.abs(y_test-y_pred_test) / y_test)* 100.)\n",
    "\n",
    "    R2_train = r2_score(y_train,y_pred_train)\n",
    "    R2_test  = r2_score(y_test,y_pred_test)\n",
    "\n",
    "    performance = pd.DataFrame({'Error_metric': ['Mean error','Mean absolute error','Mean squared error',\n",
    "                                             'Root mean squared error','Mean absolute percentual error',\n",
    "                                             'R2'],\n",
    "                            'Train': [ME_train, MAE_train, MSE_train, RMSE_train, MAPE_train, R2_train],\n",
    "                            'Test' : [ME_test, MAE_test , MSE_test, RMSE_test, MAPE_test, R2_test]})\n",
    "\n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "    df_train = pd.DataFrame({'Real': y_train.tolist(), 'Predicted': y_pred_train.tolist()})\n",
    "    df_test  = pd.DataFrame({'Real': y_test.tolist(),  'Predicted': y_pred_test.tolist()})\n",
    "\n",
    "    return performance, df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean error</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean absolute error</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean squared error</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Root mean squared error</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mean absolute percentual error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Error_metric  Train  Test\n",
       "0                      Mean error  -0.04 -0.09\n",
       "1             Mean absolute error   0.24  0.30\n",
       "2              Mean squared error   0.11  0.16\n",
       "3         Root mean squared error   0.32  0.40\n",
       "4  Mean absolute percentual error    NaN   NaN\n",
       "5                              R2   0.53  0.30"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_nn1 = model.predict(X_train)\n",
    "y_pred_test_nn1  = model.predict(X_test)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test  = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "results, df1, df2 = model_performance(y_train, y_pred_train_nn1, y_test, y_pred_test_nn1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  result\n",
       "676   1   0   1   1   0  -1   0   0   1    0.38\n",
       "765   0   1   1   0  -1  -1   0   1  -1    0.37\n",
       "253   1  -1   0   1   0  -1   1  -1  -1    1.15\n",
       "871   0  -1  -1   1   0   1   1  -1   0    0.53\n",
       "558  -1   0   1  -1   0   1  -1  -1   1    0.84\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..     ...\n",
       "71    1   1   1  -1  -1   0   0   0   1    1.07\n",
       "857   0  -1   1   0   1   1   0  -1  -1    0.92\n",
       "334   0   1   0   0   0   1   1   1   1    0.36\n",
       "499  -1   1   0   1   1   0   0   1  -1    0.80\n",
       "742   0   1   1   1   0   1  -1   0   0    0.79\n",
       "\n",
       "[288 rows x 10 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2 = X_test.copy()\n",
    "X_test_2['result'] = y_pred_test_nn1\n",
    "X_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  result\n",
       "676   1   0   1   1   0  -1   0   0   1    0.38\n",
       "765   0   1   1   0  -1  -1   0   1  -1    0.37\n",
       "253   1  -1   0   1   0  -1   1  -1  -1    1.15\n",
       "871   0  -1  -1   1   0   1   1  -1   0    0.53\n",
       "558  -1   0   1  -1   0   1  -1  -1   1    0.84\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..     ...\n",
       "71    1   1   1  -1  -1   0   0   0   1    1.07\n",
       "857   0  -1   1   0   1   1   0  -1  -1    0.92\n",
       "334   0   1   0   0   0   1   1   1   1    0.36\n",
       "499  -1   1   0   1   1   0   0   1  -1    0.80\n",
       "742   0   1   1   1   0   1  -1   0   0    0.79\n",
       "\n",
       "[288 rows x 10 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it could be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Improve Your Model\n",
    "\n",
    "Did your model achieve low loss (<0.1) and high accuracy (>0.95)? If not, try to improve your model.\n",
    "\n",
    "But how? There are so many things you can play with in Tensorflow and in the next challenge you'll learn about these things. But in this challenge, let's just do a few things to see if they will help.\n",
    "\n",
    "* Add more layers to your model. If the data are complex you need more layers. But don't use more layers than you need. If adding more layers does not improve the model performance you don't need additional layers.\n",
    "* Adjust the learning rate when you compile the model. This means you will create a custom `tf.keras.optimizers.Adam` instance where you specify the learning rate you want. Then pass the instance to `model.compile` as the optimizer.\n",
    "    * `tf.keras.optimizers.Adam` [reference](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n",
    "    * Don't worry if you don't understand what the learning rate does. You'll learn about it in the next challenge.\n",
    "* Adjust the number of epochs when you fit the training data to the model. Your model performance continues to improve as you train more epochs. But eventually it will reach the ceiling and the performance will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_84\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_328 (Dense)           (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 3)                 30        \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124\n",
      "Trainable params: 124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=5) \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Dense(units = 9,input_dim = X_train.shape[1],activation='relu'))\n",
    "model.add(Dense(units = 3,activation='relu'))\n",
    "model.add(Dense(units = 1, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam', # Optimization method\n",
    "              loss='mse', # Error metric to minimize\n",
    "              metrics=['accuracy'] # Error matrics to report. But only the \"loss\" will be used for minimization.\n",
    "              )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'reg-nn1.hdf5'\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path, # Where to save the checkpoint.\n",
    "    save_freq='epoch', # How often the checkpoint file will be saved.\n",
    "    save_weights_only=False, # Wether or not save only the weitgths of each neuron.\n",
    "    verbose=1 # To display the progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\n",
      "Epoch 1: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.3650 - accuracy: 0.4720 - val_loss: 0.3110 - val_accuracy: 0.5522 - 352ms/epoch - 3ms/step\n",
      "Epoch 2/60\n",
      "\n",
      "Epoch 2: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2966 - accuracy: 0.5560 - val_loss: 0.2599 - val_accuracy: 0.5896 - 96ms/epoch - 890us/step\n",
      "Epoch 3/60\n",
      "\n",
      "Epoch 3: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2527 - accuracy: 0.6138 - val_loss: 0.2236 - val_accuracy: 0.6194 - 102ms/epoch - 946us/step\n",
      "Epoch 4/60\n",
      "\n",
      "Epoch 4: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2273 - accuracy: 0.6567 - val_loss: 0.2101 - val_accuracy: 0.6493 - 91ms/epoch - 841us/step\n",
      "Epoch 5/60\n",
      "\n",
      "Epoch 5: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2143 - accuracy: 0.6735 - val_loss: 0.2044 - val_accuracy: 0.6791 - 104ms/epoch - 960us/step\n",
      "Epoch 6/60\n",
      "\n",
      "Epoch 6: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2060 - accuracy: 0.6978 - val_loss: 0.2020 - val_accuracy: 0.6791 - 91ms/epoch - 843us/step\n",
      "Epoch 7/60\n",
      "\n",
      "Epoch 7: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.2007 - accuracy: 0.6978 - val_loss: 0.1996 - val_accuracy: 0.6866 - 105ms/epoch - 976us/step\n",
      "Epoch 8/60\n",
      "\n",
      "Epoch 8: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1958 - accuracy: 0.7052 - val_loss: 0.1981 - val_accuracy: 0.7090 - 93ms/epoch - 857us/step\n",
      "Epoch 9/60\n",
      "\n",
      "Epoch 9: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1920 - accuracy: 0.7108 - val_loss: 0.1972 - val_accuracy: 0.7090 - 96ms/epoch - 888us/step\n",
      "Epoch 10/60\n",
      "\n",
      "Epoch 10: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1890 - accuracy: 0.7164 - val_loss: 0.1959 - val_accuracy: 0.7313 - 95ms/epoch - 876us/step\n",
      "Epoch 11/60\n",
      "\n",
      "Epoch 11: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1863 - accuracy: 0.7220 - val_loss: 0.1953 - val_accuracy: 0.7388 - 88ms/epoch - 816us/step\n",
      "Epoch 12/60\n",
      "\n",
      "Epoch 12: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1838 - accuracy: 0.7295 - val_loss: 0.1946 - val_accuracy: 0.7015 - 99ms/epoch - 915us/step\n",
      "Epoch 13/60\n",
      "\n",
      "Epoch 13: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1826 - accuracy: 0.7295 - val_loss: 0.1929 - val_accuracy: 0.7090 - 104ms/epoch - 967us/step\n",
      "Epoch 14/60\n",
      "\n",
      "Epoch 14: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1809 - accuracy: 0.7295 - val_loss: 0.1923 - val_accuracy: 0.7388 - 96ms/epoch - 891us/step\n",
      "Epoch 15/60\n",
      "\n",
      "Epoch 15: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1782 - accuracy: 0.7351 - val_loss: 0.1913 - val_accuracy: 0.7313 - 95ms/epoch - 875us/step\n",
      "Epoch 16/60\n",
      "\n",
      "Epoch 16: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1761 - accuracy: 0.7351 - val_loss: 0.1894 - val_accuracy: 0.7313 - 95ms/epoch - 879us/step\n",
      "Epoch 17/60\n",
      "\n",
      "Epoch 17: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1743 - accuracy: 0.7332 - val_loss: 0.1888 - val_accuracy: 0.7388 - 99ms/epoch - 917us/step\n",
      "Epoch 18/60\n",
      "\n",
      "Epoch 18: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1719 - accuracy: 0.7388 - val_loss: 0.1858 - val_accuracy: 0.7612 - 105ms/epoch - 973us/step\n",
      "Epoch 19/60\n",
      "\n",
      "Epoch 19: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1668 - accuracy: 0.7500 - val_loss: 0.1868 - val_accuracy: 0.7537 - 90ms/epoch - 838us/step\n",
      "Epoch 20/60\n",
      "\n",
      "Epoch 20: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1629 - accuracy: 0.7612 - val_loss: 0.1831 - val_accuracy: 0.7537 - 99ms/epoch - 916us/step\n",
      "Epoch 21/60\n",
      "\n",
      "Epoch 21: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1604 - accuracy: 0.7631 - val_loss: 0.1834 - val_accuracy: 0.7612 - 103ms/epoch - 956us/step\n",
      "Epoch 22/60\n",
      "\n",
      "Epoch 22: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1577 - accuracy: 0.7631 - val_loss: 0.1819 - val_accuracy: 0.7537 - 91ms/epoch - 843us/step\n",
      "Epoch 23/60\n",
      "\n",
      "Epoch 23: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1558 - accuracy: 0.7724 - val_loss: 0.1803 - val_accuracy: 0.7537 - 101ms/epoch - 931us/step\n",
      "Epoch 24/60\n",
      "\n",
      "Epoch 24: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1539 - accuracy: 0.7687 - val_loss: 0.1812 - val_accuracy: 0.7537 - 97ms/epoch - 897us/step\n",
      "Epoch 25/60\n",
      "\n",
      "Epoch 25: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1519 - accuracy: 0.7780 - val_loss: 0.1772 - val_accuracy: 0.7612 - 82ms/epoch - 756us/step\n",
      "Epoch 26/60\n",
      "\n",
      "Epoch 26: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1495 - accuracy: 0.7799 - val_loss: 0.1783 - val_accuracy: 0.7612 - 89ms/epoch - 827us/step\n",
      "Epoch 27/60\n",
      "\n",
      "Epoch 27: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1487 - accuracy: 0.7761 - val_loss: 0.1754 - val_accuracy: 0.7612 - 98ms/epoch - 909us/step\n",
      "Epoch 28/60\n",
      "\n",
      "Epoch 28: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1470 - accuracy: 0.7854 - val_loss: 0.1739 - val_accuracy: 0.7687 - 91ms/epoch - 841us/step\n",
      "Epoch 29/60\n",
      "\n",
      "Epoch 29: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1459 - accuracy: 0.7929 - val_loss: 0.1746 - val_accuracy: 0.7612 - 95ms/epoch - 877us/step\n",
      "Epoch 30/60\n",
      "\n",
      "Epoch 30: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1449 - accuracy: 0.7929 - val_loss: 0.1738 - val_accuracy: 0.7687 - 106ms/epoch - 980us/step\n",
      "Epoch 31/60\n",
      "\n",
      "Epoch 31: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1441 - accuracy: 0.7854 - val_loss: 0.1710 - val_accuracy: 0.7836 - 95ms/epoch - 877us/step\n",
      "Epoch 32/60\n",
      "\n",
      "Epoch 32: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1433 - accuracy: 0.7873 - val_loss: 0.1691 - val_accuracy: 0.7836 - 94ms/epoch - 874us/step\n",
      "Epoch 33/60\n",
      "\n",
      "Epoch 33: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1413 - accuracy: 0.7910 - val_loss: 0.1675 - val_accuracy: 0.7836 - 106ms/epoch - 981us/step\n",
      "Epoch 34/60\n",
      "\n",
      "Epoch 34: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1429 - accuracy: 0.7948 - val_loss: 0.1644 - val_accuracy: 0.7910 - 96ms/epoch - 888us/step\n",
      "Epoch 35/60\n",
      "\n",
      "Epoch 35: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1395 - accuracy: 0.7966 - val_loss: 0.1661 - val_accuracy: 0.7836 - 95ms/epoch - 880us/step\n",
      "Epoch 36/60\n",
      "\n",
      "Epoch 36: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1389 - accuracy: 0.7966 - val_loss: 0.1667 - val_accuracy: 0.7910 - 97ms/epoch - 900us/step\n",
      "Epoch 37/60\n",
      "\n",
      "Epoch 37: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1388 - accuracy: 0.7985 - val_loss: 0.1639 - val_accuracy: 0.7985 - 87ms/epoch - 810us/step\n",
      "Epoch 38/60\n",
      "\n",
      "Epoch 38: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1366 - accuracy: 0.8078 - val_loss: 0.1629 - val_accuracy: 0.7910 - 90ms/epoch - 835us/step\n",
      "Epoch 39/60\n",
      "\n",
      "Epoch 39: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1358 - accuracy: 0.8134 - val_loss: 0.1636 - val_accuracy: 0.7910 - 97ms/epoch - 901us/step\n",
      "Epoch 40/60\n",
      "\n",
      "Epoch 40: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1352 - accuracy: 0.7985 - val_loss: 0.1610 - val_accuracy: 0.7836 - 82ms/epoch - 761us/step\n",
      "Epoch 41/60\n",
      "\n",
      "Epoch 41: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1333 - accuracy: 0.8060 - val_loss: 0.1634 - val_accuracy: 0.7687 - 86ms/epoch - 799us/step\n",
      "Epoch 42/60\n",
      "\n",
      "Epoch 42: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1338 - accuracy: 0.8022 - val_loss: 0.1600 - val_accuracy: 0.7910 - 91ms/epoch - 845us/step\n",
      "Epoch 43/60\n",
      "\n",
      "Epoch 43: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1324 - accuracy: 0.8172 - val_loss: 0.1591 - val_accuracy: 0.7985 - 92ms/epoch - 851us/step\n",
      "Epoch 44/60\n",
      "\n",
      "Epoch 44: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1308 - accuracy: 0.8116 - val_loss: 0.1603 - val_accuracy: 0.7910 - 101ms/epoch - 937us/step\n",
      "Epoch 45/60\n",
      "\n",
      "Epoch 45: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1306 - accuracy: 0.8190 - val_loss: 0.1580 - val_accuracy: 0.7910 - 95ms/epoch - 879us/step\n",
      "Epoch 46/60\n",
      "\n",
      "Epoch 46: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1298 - accuracy: 0.8284 - val_loss: 0.1600 - val_accuracy: 0.7985 - 100ms/epoch - 923us/step\n",
      "Epoch 47/60\n",
      "\n",
      "Epoch 47: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1288 - accuracy: 0.8153 - val_loss: 0.1580 - val_accuracy: 0.8060 - 100ms/epoch - 925us/step\n",
      "Epoch 48/60\n",
      "\n",
      "Epoch 48: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1279 - accuracy: 0.8134 - val_loss: 0.1563 - val_accuracy: 0.7985 - 93ms/epoch - 862us/step\n",
      "Epoch 49/60\n",
      "\n",
      "Epoch 49: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1284 - accuracy: 0.8284 - val_loss: 0.1574 - val_accuracy: 0.7985 - 96ms/epoch - 889us/step\n",
      "Epoch 50/60\n",
      "\n",
      "Epoch 50: saving model to reg-nn1.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 0s - loss: 0.1253 - accuracy: 0.8302 - val_loss: 0.1580 - val_accuracy: 0.8060 - 105ms/epoch - 970us/step\n",
      "Epoch 51/60\n",
      "\n",
      "Epoch 51: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1243 - accuracy: 0.8284 - val_loss: 0.1570 - val_accuracy: 0.8060 - 100ms/epoch - 927us/step\n",
      "Epoch 52/60\n",
      "\n",
      "Epoch 52: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1240 - accuracy: 0.8340 - val_loss: 0.1548 - val_accuracy: 0.8060 - 92ms/epoch - 850us/step\n",
      "Epoch 53/60\n",
      "\n",
      "Epoch 53: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1221 - accuracy: 0.8284 - val_loss: 0.1553 - val_accuracy: 0.7985 - 90ms/epoch - 835us/step\n",
      "Epoch 54/60\n",
      "\n",
      "Epoch 54: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1210 - accuracy: 0.8377 - val_loss: 0.1518 - val_accuracy: 0.8060 - 100ms/epoch - 925us/step\n",
      "Epoch 55/60\n",
      "\n",
      "Epoch 55: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1196 - accuracy: 0.8489 - val_loss: 0.1524 - val_accuracy: 0.8060 - 97ms/epoch - 900us/step\n",
      "Epoch 56/60\n",
      "\n",
      "Epoch 56: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1183 - accuracy: 0.8396 - val_loss: 0.1514 - val_accuracy: 0.8134 - 89ms/epoch - 820us/step\n",
      "Epoch 57/60\n",
      "\n",
      "Epoch 57: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1168 - accuracy: 0.8451 - val_loss: 0.1508 - val_accuracy: 0.8209 - 95ms/epoch - 878us/step\n",
      "Epoch 58/60\n",
      "\n",
      "Epoch 58: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1159 - accuracy: 0.8545 - val_loss: 0.1499 - val_accuracy: 0.8134 - 84ms/epoch - 780us/step\n",
      "Epoch 59/60\n",
      "\n",
      "Epoch 59: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1153 - accuracy: 0.8433 - val_loss: 0.1500 - val_accuracy: 0.8134 - 91ms/epoch - 841us/step\n",
      "Epoch 60/60\n",
      "\n",
      "Epoch 60: saving model to reg-nn1.hdf5\n",
      "108/108 - 0s - loss: 0.1147 - accuracy: 0.8526 - val_loss: 0.1474 - val_accuracy: 0.8134 - 83ms/epoch - 767us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=60, # Number of epochs. \n",
    "    validation_split=0.20, # Here the TRAIN set will be split in TRAIN = TRAIN_NEW + VALIDATION. TRAIN_NEW used for train and val for CV\n",
    "    batch_size=5, # How many samples to input in the network before updating the weights\n",
    "    verbose=2, # To display the progress.\n",
    "    callbacks=[early_stopping,checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(history,'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach(es) did you find helpful to improve your model performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean error</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean absolute error</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mean squared error</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Root mean squared error</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mean absolute percentual error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Error_metric  Train  Test\n",
       "0                      Mean error  -0.01 -0.07\n",
       "1             Mean absolute error   0.26  0.34\n",
       "2              Mean squared error   0.12  0.19\n",
       "3         Root mean squared error   0.34  0.44\n",
       "4  Mean absolute percentual error    NaN   NaN\n",
       "5                              R2   0.47  0.19"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train_nn1 = model.predict(X_train)\n",
    "y_pred_test_nn1  = model.predict(X_test)\n",
    "\n",
    "y_train = np.array(y_train).reshape(-1,1)\n",
    "y_test  = np.array(y_test).reshape(-1,1)\n",
    "\n",
    "results, df1, df2 = model_performance(y_train, y_pred_train_nn1, y_test, y_pred_test_nn1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TL</th>\n",
       "      <th>TM</th>\n",
       "      <th>TR</th>\n",
       "      <th>ML</th>\n",
       "      <th>MM</th>\n",
       "      <th>MR</th>\n",
       "      <th>BL</th>\n",
       "      <th>BM</th>\n",
       "      <th>BR</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TL  TM  TR  ML  MM  MR  BL  BM  BR  result\n",
       "676   1   0   1   1   0  -1   0   0   1    0.66\n",
       "765   0   1   1   0  -1  -1   0   1  -1    0.62\n",
       "253   1  -1   0   1   0  -1   1  -1  -1    0.84\n",
       "871   0  -1  -1   1   0   1   1  -1   0    0.73\n",
       "558  -1   0   1  -1   0   1  -1  -1   1    1.00\n",
       "..   ..  ..  ..  ..  ..  ..  ..  ..  ..     ...\n",
       "71    1   1   1  -1  -1   0   0   0   1    0.61\n",
       "857   0  -1   1   0   1   1   0  -1  -1    0.89\n",
       "334   0   1   0   0   0   1   1   1   1    0.40\n",
       "499  -1   1   0   1   1   0   0   1  -1    0.52\n",
       "742   0   1   1   1   0   1  -1   0   0    0.47\n",
       "\n",
       "[288 rows x 10 columns]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2 = X_test.copy()\n",
    "X_test_2['result'] = y_pred_test_nn1\n",
    "X_test_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not the best result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
